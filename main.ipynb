{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5 Threat hunting\n",
    "\n",
    "## Diego Franco 20240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import json\n",
    "import random\n",
    "from clasificador import *\n",
    "import csv\n",
    "import whois"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leer el json con la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad total de registros: 746909\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Paso 1: Definir la ubicación del archivo\n",
    "archivo = \"Archivos/large_eve.json\"\n",
    "\n",
    "# Paso 2: Cargar el archivo JSON en una lista de diccionarios\n",
    "with open(archivo, 'r') as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "# Paso 3: Obtener la cantidad total de registros\n",
    "cantidad_total_registros = len(data)\n",
    "print(\"Cantidad total de registros:\", cantidad_total_registros)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtener unicamente los DNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros DNS: 15749\n"
     ]
    }
   ],
   "source": [
    "# Filtrar la lista de diccionarios para obtener registros DNS\n",
    "registros_dns = [registro for registro in data if 'event_type' in registro and 'dns' in registro['event_type'].lower()]\n",
    "\n",
    "# Obtener la cantidad de registros DNS\n",
    "cantidad_registros_dns = len(registros_dns)\n",
    "print(\"Cantidad de registros DNS:\", cantidad_registros_dns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mostrar 2 registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'timestamp': '2017-07-22T18:29:17.502533-0500', 'flow_id': 333716841671229, 'pcap_cnt': 504853, 'event_type': 'dns', 'vlan': 150, 'src_ip': '192.168.207.4', 'src_port': 53, 'dest_ip': '192.168.205.188', 'dest_port': 39689, 'proto': 'UDP', 'dns': {'type': 'answer', 'id': 2970, 'rcode': 'NXDOMAIN', 'rrname': '<root>', 'rrtype': 'SOA', 'ttl': 20864}}\n",
      "{'timestamp': '2017-07-22T18:29:17.763025-0500', 'flow_id': 1916096610149321, 'pcap_cnt': 505384, 'event_type': 'dns', 'vlan': 150, 'src_ip': '192.168.207.4', 'src_port': 53, 'dest_ip': '192.168.205.188', 'dest_port': 54263, 'proto': 'UDP', 'dns': {'type': 'answer', 'id': 41704, 'rcode': 'NXDOMAIN', 'rrname': '<root>', 'rrtype': 'SOA', 'ttl': 20864}}\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar dos registros aleatorios de registros_dns\n",
    "dos_registros_cualesquiera = random.sample(registros_dns, 2)\n",
    "\n",
    "# Imprimir los dos registros seleccionados\n",
    "for registro in dos_registros_cualesquiera:\n",
    "    print(registro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertir a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape del DataFrame: (15749, 18)\n"
     ]
    }
   ],
   "source": [
    "# Normalizar la información contenida en los JSON anidados y asignarla a un DataFrame\n",
    "df_normalized = json_normalize(registros_dns)\n",
    "\n",
    "# Mostrar la forma (shape) del DataFrame\n",
    "print(\"Shape del DataFrame:\", df_normalized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape del DataFrame con registros DNS tipo A: (2849, 18)\n"
     ]
    }
   ],
   "source": [
    "# Filtrar los registros DNS tipo A\n",
    "registros_dns_tipo_a = df_normalized[df_normalized['dns.rrtype'] == 'A']\n",
    "\n",
    "print(\"Shape del DataFrame con registros DNS tipo A:\", registros_dns_tipo_a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrar dominios unicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de dominios únicos: 177\n"
     ]
    }
   ],
   "source": [
    "dominios_unicos = registros_dns_tipo_a['dns.rrname'].unique()\n",
    "print(\"Cantidad de dominios únicos:\", len(dominios_unicos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_tld(dominio):\n",
    "    \"\"\"\n",
    "    Función para obtener el TLD (Dominio de Nivel Superior) de un dominio dado.\n",
    "    \n",
    "    Args:\n",
    "    - dominio (str): El dominio del cual se quiere obtener el TLD.\n",
    "    \n",
    "    Returns:\n",
    "    - str: El TLD del dominio.\n",
    "    \"\"\"\n",
    "    partes = dominio.split('.')\n",
    "    for i in range(len(partes) - 1, 0, -1):\n",
    "        # Recorrer las partes del dominio en orden inverso\n",
    "        tld_potencial = '.'.join(partes[i:])\n",
    "        if tld_potencial in [\"com\", \"net\", \"org\", \"gov\", \"edu\", \"mil\", \"arpa\", \"int\"]:\n",
    "            continue  # Si el segmento es un TLD válido, continuar buscando\n",
    "        else:\n",
    "            return tld_potencial  # Si no es un TLD válido, devolver este segmento como el TLD\n",
    "    return dominio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           domain_tld\n",
      "0    wunderground.com\n",
      "1         dropbox.com\n",
      "2           aoltw.net\n",
      "3                home\n",
      "4         mozilla.com\n",
      "..                ...\n",
      "172       localdomain\n",
      "173     microsoft.com\n",
      "174      verisign.com\n",
      "175    stayonline.net\n",
      "176          real.com\n",
      "\n",
      "[177 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Aplicar la función obtener_tld a cada dominio único\n",
    "tlds = [obtener_tld(dominio) for dominio in dominios_unicos]\n",
    "\n",
    "# Crear un nuevo DataFrame solo con la columna domain_tld\n",
    "df_tlds = pd.DataFrame({'domain_tld': tlds})\n",
    "\n",
    "print(df_tlds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizar el clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           domain_tld  isDGA\n",
      "0    wunderground.com      0\n",
      "1         dropbox.com      1\n",
      "2           aoltw.net      1\n",
      "3                home      0\n",
      "4         mozilla.com      0\n",
      "..                ...    ...\n",
      "172       localdomain      0\n",
      "173     microsoft.com      1\n",
      "174      verisign.com      0\n",
      "175    stayonline.net      0\n",
      "176          real.com      1\n",
      "\n",
      "[177 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diego\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:299: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.0.2 when using version 1.2.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_resultado = clasificacion(df_tlds)\n",
    "\n",
    "print(df_resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_dga = df_resultado[df_resultado['isDGA'] == 1]\n",
    "\n",
    "df_dga_unicos = df_dga.drop_duplicates()\n",
    "\n",
    "print(len(df_dga_unicos))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrar con la lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_tld(tld):\n",
    "    \"\"\"\n",
    "    Función para verificar si un TLD se encuentra en una lista de TLDs proporcionada en un archivo CSV.\n",
    "\n",
    "    Args:\n",
    "    - tld (str): El TLD que se desea verificar.\n",
    "\n",
    "    Returns:\n",
    "    - int: 0 si el TLD está en la lista, 1 si no está.\n",
    "    \"\"\"\n",
    "    # Ruta al archivo CSV que contiene la lista de TLDs\n",
    "    archivo_tlds = 'top-1m.csv'\n",
    "\n",
    "    # Intentamos abrir el archivo y verificar si el TLD está en la lista\n",
    "    try:\n",
    "        with open(archivo_tlds, 'r') as f:\n",
    "            for linea in f:\n",
    "                if linea.strip().endswith(tld.lower()):\n",
    "                    return 0  # El TLD está en la lista\n",
    "            return 1  # El TLD no está en la lista\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: No se pudo encontrar el archivo de lista de TLDs.\")\n",
    "        return -1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "         domain_tld  isDGA  en_lista\n",
      "1       dropbox.com      1         0\n",
      "5    metasploit.com      1         0\n",
      "25      windows.com      1         0\n",
      "48   phpmyadmin.net      1         0\n",
      "51    microsoft.com      1         0\n",
      "60   postgresql.org      1         0\n",
      "62      freepbx.org      1         0\n",
      "78       flickr.com      1         0\n",
      "83     facebook.com      1         0\n",
      "87       xmarks.com      1         0\n",
      "92        adams.net      1         0\n",
      "95     clarkson.edu      1         0\n",
      "98         wisc.edu      1         0\n",
      "100    easynews.com      1         0\n",
      "101    bluehost.com      1         0\n",
      "106      kernel.org      1         0\n",
      "108   liquidweb.com      1         0\n",
      "114  team-cymru.org      1         0\n",
      "117    xmission.com      1         0\n",
      "127       apple.com      1         0\n",
      "144    msftncsi.com      1         0\n",
      "176        real.com      1         0\n"
     ]
    }
   ],
   "source": [
    "# Crear una copia del DataFrame df_dga_unicos\n",
    "df_dga_unicos_copia = df_dga_unicos.copy()\n",
    "\n",
    "df_dga_unicos_copia['en_lista'] = df_dga_unicos_copia['domain_tld'].apply(verificar_tld)\n",
    "\n",
    "df_en_lista = df_dga_unicos_copia[df_dga_unicos_copia['en_lista'] == 0]\n",
    "\n",
    "print(len(df_en_lista))\n",
    "\n",
    "df_en_lista_sin_duplicados = df_en_lista.drop_duplicates(subset='domain_tld')\n",
    "\n",
    "print(df_en_lista_sin_duplicados)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whois\n",
    "from datetime import datetime\n",
    "\n",
    "def obtener_fecha_creacion_tld(tld):\n",
    "\n",
    "    try:\n",
    "        # Realizar la consulta WHOIS para el TLD proporcionado\n",
    "        w = whois.whois(tld)\n",
    "\n",
    "#Obtener la fecha de creación desde el objeto WHOIS\n",
    "        fecha_creacion = w.creation_date\n",
    "\n",
    "#La fecha de creación puede ser una lista o un solo valor, dependiendo del TLD\n",
    "        if isinstance(fecha_creacion, list):\n",
    "            fecha_creacion = fecha_creacion[0]\n",
    "\n",
    "#Formatear la fecha de creación como string en formato 'YYYY-MM-DD'\n",
    "        if fecha_creacion:\n",
    "            if isinstance(fecha_creacion, datetime):\n",
    "                return fecha_creacion.strftime('%Y-%m-%d')\n",
    "            else:\n",
    "                return str(fecha_creacion)\n",
    "        else:\n",
    "            return \"No se pudo encontrar la fecha de creación.\"\n",
    "    except Exception as e:\n",
    "        return \"Error al buscar la fecha de creación: \" + str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         domain_tld  isDGA  en_lista fecha_creacion\n",
      "1       dropbox.com      1         0     1995-06-28\n",
      "5    metasploit.com      1         0     2003-06-10\n",
      "25      windows.com      1         0     1995-09-11\n",
      "48   phpmyadmin.net      1         0     2002-04-02\n",
      "51    microsoft.com      1         0     1991-05-02\n",
      "60   postgresql.org      1         0     1996-10-22\n",
      "62      freepbx.org      1         0     2005-10-11\n",
      "78       flickr.com      1         0     2003-11-22\n",
      "83     facebook.com      1         0     1997-03-29\n",
      "87       xmarks.com      1         0     2003-12-29\n",
      "92        adams.net      1         0     1994-12-23\n",
      "95     clarkson.edu      1         0     1986-11-21\n",
      "98         wisc.edu      1         0     1985-09-30\n",
      "100    easynews.com      1         0     1996-10-31\n",
      "101    bluehost.com      1         0     2002-11-15\n",
      "106      kernel.org      1         0     1997-03-07\n",
      "108   liquidweb.com      1         0     1997-08-05\n",
      "114  team-cymru.org      1         0     2004-08-04\n",
      "117    xmission.com      1         0     1994-03-25\n",
      "127       apple.com      1         0     1987-02-19\n",
      "144    msftncsi.com      1         0     2005-11-10\n",
      "176        real.com      1         0     1996-12-24\n"
     ]
    }
   ],
   "source": [
    "df_en_lista_sin_duplicados['fecha_creacion'] = df_en_lista_sin_duplicados['domain_tld'].apply(obtener_fecha_creacion_tld)\n",
    "\n",
    "# Mostrar el DataFrame con la fecha de creación\n",
    "print(df_en_lista_sin_duplicados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dominios sospechosos\n",
    "\n",
    "Se puede confirmar como dominio sospechoso:\n",
    "- 11\n",
    "- 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt utilizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aqui"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
